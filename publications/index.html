<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Guan-Horng Liu   | Publications</title>
<meta name="description" content="Machine Learning PhD @ Georgia Tech ðŸš€">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<!-- <link rel="stylesheet" href="https://gitcdn.xyz/repo/jwarby/jekyll-pygments-themes/master/.css" /> -->

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸš€</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-131922969-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-131922969-1');
  </script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Guan-Horng Liu</span>   
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>

          <li class="nav-item">
            <a class="nav-link" href="https://ghliu.github.io/assets/pdf/cv.pdf" target="\_blank">CV</a>
            <!-- <a class="nav-link" href=  "https://ghliu.github.io/assets/pub/CV-2020.pdf" target="\_blank">CV</a> -->
          </li>

          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">Publications</h1>
    <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-md-2 abbr">
  
    
    <abbr class="badge">NeurIPS 2021</abbr>
    <!-- <div class="award">(Oral)</div> -->
    
  
  </div>

  <div id="liu2021second" class="col-md-9">
    
      <div class="title">Second-order Neural ODE Optimizer</div>
      <div class="author">
        
          
          
          
          

          
            
              
                <em>Guan-Horng Liu</em>,
              
            
          
        
          
          
          
          

          
            
              
                
                  Tianrong Chen,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and Evangelos A Theodorou
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Conference on Neural Information Processing Systems</em>,
      
      
        2021
      
      </div>
      
        <div class="awardNote">Spotlight presentation (acceptance rate 3.0%)</div>
      
    



    <div class="links">
    <a class="cite btn btn-sm z-depth-0" role="button">bibtex</a>
    
      <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
    
    
      <a href="http://arxiv.org/abs/2109.14158" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We propose a novel second-order optimization framework for training the emerging deep continuous-time models, specifically the Neural Ordinary Differential Equations (Neural ODEs). Since their training already involves expensive gradient computation by solving a backward ODE, deriving efficient second-order methods becomes highly nontrivial. Nevertheless, inspired by the recent Optimal Control (OC) interpretation of training deep networks, we show that a specific continuous-time OC methodology, called Differential Programming, can be adopted to derive backward ODEs for higher-order derivatives at the same O(1) memory cost. We further explore a low-rank representation of the second-order derivatives and show that it leads to efficient preconditioned updates with the aid of Kronecker-based factorization. The resulting method converges much faster than first-order baselines in wall-clock time, and the improvement remains consistent across various applications, e.g. image classification, generative flow, and time-series prediction. Our framework also enables direct architecture optimization, such as the integration time of Neural ODEs, with second-order feedback policies, strengthening the OC perspective as a principled tool of analyzing optimization in deep learning. </p>
    </div>
    
    <!-- Hidden abstract block -->

    <div class="cite hidden">
      <p>&#64;inproceedings&#123;liu2021second,<br />
         &nbsp; title=&#123;Second-order Neural ODE Optimizer&#125;,<br />
         &nbsp; author=&#123;Liu, Guan-Horng and Chen, Tianrong and Theodorou, Evangelos A&#125;,<br />
         
            &nbsp; booktitle=&#123;Conference on Neural Information Processing Systems&#125;,<br />
         
         &nbsp; year=&#123;2021&#125;,<br />
         &#125;
      </p>
    </div>

  </div>
</div>
</li>
<li><div class="row">
  <div class="col-md-2 abbr">
  
    
    <abbr class="badge">ICML 2021</abbr>
    <!-- <div class="award">(Oral)</div> -->
    
  
  </div>

  <div id="liu2021dynamic" class="col-md-9">
    
      <div class="title">Dynamic Game Theoretic Neural Optimizer</div>
      <div class="author">
        
          
          
          
          

          
            
              
                <em>Guan-Horng Liu</em>,
              
            
          
        
          
          
          
          

          
            
              
                
                  Tianrong Chen,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and Evangelos A Theodorou
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>International Conference on Machine Learning</em>,
      
      
        2021
      
      </div>
      
        <div class="awardNote">Oral presentation (acceptance rate 3.0%)</div>
      
    



    <div class="links">
    <a class="cite btn btn-sm z-depth-0" role="button">bibtex</a>
    
      <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
    
    
      <a href="http://arxiv.org/abs/2105.03788" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="http://proceedings.mlr.press/v139/liu21d/liu21d.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      
      <a href="https://docs.google.com/presentation/d/1Pm-5h_0jji6ocsarzhdjXZpBpTtwr9kx44fyyU67hH4/edit?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
      
      <a href="https://icml.cc/media/icml-2021/Slides/10261.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    
      <a href="https://icml.cc/virtual/2021/poster/10261" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The connection between training deep neural networks (DNNs) and optimal control theory (OCT) has attracted considerable attention as a principled tool of algorithmic design. Despite few attempts being made, they have been limited to architectures where the layer propagation resembles a Markovian dynamical system. This casts doubts on their flexibility to modern networks that heavily rely on non-Markovian dependencies between layers (e.g. skip connections in residual networks). In this work, we propose a novel dynamic game perspective by viewing each layer as a player in a dynamic game characterized by the DNN itself. Through this lens, different classes of optimizers can be seen as matching different types of Nash equilibria, depending on the implicit information structure of each (p)layer. The resulting method, called Dynamic Game Theoretic Neural Optimizer (DGNOpt), not only generalizes OCT-inspired optimizers to richer network class; it also motivates a new training principle by solving a multi-player cooperative game. DGNOpt shows convergence improvements over existing methods on image classification datasets with residual networks. Our work marries strengths from both OCT and game theory, paving ways to new algorithmic opportunities from robust optimal control and bandit-based optimization. </p>
    </div>
    
    <!-- Hidden abstract block -->

    <div class="cite hidden">
      <p>&#64;inproceedings&#123;liu2021dynamic,<br />
         &nbsp; title=&#123;Dynamic Game Theoretic Neural Optimizer&#125;,<br />
         &nbsp; author=&#123;Liu, Guan-Horng and Chen, Tianrong and Theodorou, Evangelos A&#125;,<br />
         
            &nbsp; booktitle=&#123;International Conference on Machine Learning&#125;,<br />
         
         &nbsp; year=&#123;2021&#125;,<br />
         &#125;
      </p>
    </div>

  </div>
</div>
</li>
<li><div class="row">
  <div class="col-md-2 abbr">
  
    
    <abbr class="badge">ICLR 2021</abbr>
    <!-- <div class="award">(Spotlight)</div> -->
    
  
  </div>

  <div id="liu2021differential" class="col-md-9">
    
      <div class="title">DDPNOpt: Differential Dynamic Programming Neural Optimizer</div>
      <div class="author">
        
          
          
          
          

          
            
              
                <em>Guan-Horng Liu</em>,
              
            
          
        
          
          
          
          

          
            
              
                
                  Tianrong Chen,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and Evangelos A Theodorou
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>International Conference on Learning Representations</em>,
      
      
        2021
      
      </div>
      
        <div class="awardNote">Spotlight presentation (acceptance rate 3.8%)</div>
      
    



    <div class="links">
    <a class="cite btn btn-sm z-depth-0" role="button">bibtex</a>
    
      <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
    
    
      <a href="http://arxiv.org/abs/2002.08809" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="https://openreview.net/pdf?id=6s7ME_X5_Un" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      
      <a href="https://docs.google.com/presentation/d/1OBW4bXZMDp27smv0za15EjnOV07jC1TpIwA0ww-vlyM/edit?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
      
      <a href="https://drive.google.com/file/d/1hCMEGjE5Zt6WYN4TUAAsvj9QlxhsTlHG/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    
      <a href="https://iclr.cc/virtual/2021/spotlight/3512" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Interpretation of Deep Neural Networks (DNNs) training as an optimal control problem with nonlinear dynamical systems has received considerable attention recently, yet the algorithmic development remains relatively limited. In this work, we make an attempt along this line by reformulating the training procedure from the trajectory optimization perspective. We first show that most widely-used algorithms for training DNNs can be linked to the Differential Dynamic Programming (DDP), a celebrated second-order method rooted in the Approximate Dynamic Programming. In this vein, we propose a new class of optimizer, DDP Neural Optimizer (DDPNOpt), for training feedforward and convolution networks. DDPNOpt features layer-wise feedback policies which improve convergence and reduce sensitivity to hyper-parameter over existing methods. It outperforms other optimal-control inspired training methods in both convergence and complexity, and is competitive against state-of-the-art first and second order methods. We also observe DDPNOpt has surprising benefit in preventing gradient vanishing. Our work opens up new avenues for principled algorithmic design built upon the optimal control theory.</p>
    </div>
    
    <!-- Hidden abstract block -->

    <div class="cite hidden">
      <p>&#64;inproceedings&#123;liu2021differential,<br />
         &nbsp; title=&#123;DDPNOpt: Differential Dynamic Programming Neural Optimizer&#125;,<br />
         &nbsp; author=&#123;Liu, Guan-Horng and Chen, Tianrong and Theodorou, Evangelos A&#125;,<br />
         
            &nbsp; booktitle=&#123;International Conference on Learning Representations&#125;,<br />
         
         &nbsp; year=&#123;2021&#125;,<br />
         &#125;
      </p>
    </div>

  </div>
</div>
</li>
<li><div class="row">
  <div class="col-md-2 abbr">
  
    
    <abbr class="badge">arxiv</abbr>
    <!-- <div class="award"></div> -->
    
  
  </div>

  <div id="evans2021spatio" class="col-md-9">
    
      <div class="title">Spatio-Temporal Differential Dynamic Programming for Control of Fields</div>
      <div class="author">
        
          
          
          
          

          
            
              
                
                  Ethan N Evans,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Oswin So,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Andrew P Kendall,
                
              
            
          
        
          
          
          
          

          
            
              
                <em>Guan-Horng Liu</em>,
              
            
          
        
          
          
          
          

          
            
              
                
                  and Evangelos A Theodorou
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint (in submission)</em>,
      
      
        2021
      
      </div>
      
    



    <div class="links">
    <a class="cite btn btn-sm z-depth-0" role="button">bibtex</a>
    
      <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
    
    
      <a href="http://arxiv.org/abs/2104.04044" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We consider the optimal control problem of a general nonlinear spatio-temporal system described by Partial Differential Equations (PDEs). Theory and algorithms for control of spatio-temporal systems are of rising interest among the automatic control community and exhibit numerous challenging characteristic from a control standpoint. Recent methods focus on finite-dimensional optimization techniques of a discretized finite dimensional ODE approximation of the infinite dimensional PDE system. In this paper, we derive a differential dynamic programming (DDP) framework for distributed and boundary control of spatio-temporal systems in infinite dimensions that is shown to generalize both the spatio-temporal LQR solution, and modern finite dimensional DDP frameworks. We analyze the convergence behavior and provide a proof of global convergence for the resulting system of continuous-time forward-backward equations. We explore and develop numerical approaches to handle sensitivities that arise during implementation, and apply the resulting STDDP algorithm to a linear and nonlinear spatio-temporal PDE system. Our framework is derived in infinite dimensional Hilbert spaces, and represents a discretization-agnostic framework for control of nonlinear spatio-temporal PDE systems.</p>
    </div>
    
    <!-- Hidden abstract block -->

    <div class="cite hidden">
      <p>&#64;article&#123;evans2021spatio,<br />
         &nbsp; title=&#123;Spatio-Temporal Differential Dynamic Programming for Control of Fields&#125;,<br />
         &nbsp; author=&#123;Evans, Ethan N and So, Oswin and Kendall, Andrew P and Liu, Guan-Horng and Theodorou, Evangelos A&#125;,<br />
         
            &nbsp; journal=&#123;arXiv preprint arXiv:2104.04044&#125;,<br />
         
         &nbsp; year=&#123;2021&#125;,<br />
         &#125;
      </p>
    </div>

  </div>
</div>
</li>
<li><div class="row">
  <div class="col-md-2 abbr">
  
    
    <abbr class="badge">RSS 2021</abbr>
    <!-- <div class="award"></div> -->
    
  
  </div>

  <div id="wang2021variational" class="col-md-9">
    
      <div class="title">Variational Inference MPC using Tsallis Divergence</div>
      <div class="author">
        
          
          
          
          

          
            
              
                
                  Ziyi Wang,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Oswin So,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Jason Gibson,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Bogdan Vlahov,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Manan S Gandhi,
                
              
            
          
        
          
          
          
          

          
            
              
                <em>Guan-Horng Liu</em>,
              
            
          
        
          
          
          
          

          
            
              
                
                  and Evangelos A Theodorou
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Robotics: Science and Systems</em>,
      
      
        2021
      
      </div>
      
    



    <div class="links">
    <a class="cite btn btn-sm z-depth-0" role="button">bibtex</a>
    
      <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
    
    
      <a href="http://arxiv.org/abs/2104.00241" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this paper, we provide a generalized framework for Variational Inference-Stochastic Optimal Control by using thenon-extensive Tsallis divergence. By incorporating the deformed exponential function into the optimality likelihood function, a novel Tsallis Variational Inference-Model Predictive Control algorithm is derived, which includes prior works such as Variational Inference-Model Predictive Control, Model Predictive PathIntegral Control, Cross Entropy Method, and Stein VariationalInference Model Predictive Control as special cases. The proposed algorithm allows for effective control of the cost/reward transform and is characterized by superior performance in terms of mean and variance reduction of the associated cost. The aforementioned features are supported by a theoretical and numerical analysis on the level of risk sensitivity of the proposed algorithm as well as simulation experiments on 5 different robotic systems with 3 different policy parameterizations.</p>
    </div>
    
    <!-- Hidden abstract block -->

    <div class="cite hidden">
      <p>&#64;inproceedings&#123;wang2021variational,<br />
         &nbsp; title=&#123;Variational Inference MPC using Tsallis Divergence&#125;,<br />
         &nbsp; author=&#123;Wang, Ziyi and So, Oswin and Gibson, Jason and Vlahov, Bogdan and Gandhi, Manan S and Liu, Guan-Horng and Theodorou, Evangelos A&#125;,<br />
         
            &nbsp; booktitle=&#123;Robotics: Science and Systems&#125;,<br />
         
         &nbsp; year=&#123;2021&#125;,<br />
         &#125;
      </p>
    </div>

  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-md-2 abbr">
  
    
    <abbr class="badge">arxiv</abbr>
    <!-- <div class="award"></div> -->
    
  
  </div>

  <div id="liu2020differential" class="col-md-9">
    
      <div class="title">A Differential Game Theoretic Neural Optimizer for Training Residual Networks</div>
      <div class="author">
        
          
          
          
          

          
            
              
                <em>Guan-Horng Liu</em>,
              
            
          
        
          
          
          
          

          
            
              
                
                  Tianrong Chen,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and Evangelos A Theodorou
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint</em>,
      
      
        2020
      
      </div>
      
    



    <div class="links">
    <a class="cite btn btn-sm z-depth-0" role="button">bibtex</a>
    
      <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
    
    
      <a href="http://arxiv.org/abs/2007.08880" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Connections between Deep Neural Networks (DNNs) training and optimal control theory has attracted considerable attention as a principled tool of algorithmic design. Differential Dynamic Programming (DDP) neural optimizer is a recently proposed method along this line. Despite its empirical success, the applicability has been limited to feedforward networks and whether such a trajectory-optimization inspired framework can be extended to modern architectures remains unclear. In this work, we derive a generalized DDP optimizer that accepts both residual connections and convolution layers. The resulting optimal control representation admits a game theoretic perspective, in which training residual networks can be interpreted as cooperative trajectory optimization on state-augmented dynamical systems. This Game Theoretic DDP (GT-DDP) optimizer enjoys the same theoretic connection in previous work, yet generates a much complex update rule that better leverages available information during network propagation. Evaluation on image classification datasets (e.g. MNIST and CIFAR100) shows an improvement in training convergence and variance reduction over existing methods. Our approach highlights the benefit gained from architecture-aware optimization.</p>
    </div>
    
    <!-- Hidden abstract block -->

    <div class="cite hidden">
      <p>&#64;article&#123;liu2020differential,<br />
         &nbsp; title=&#123;A Differential Game Theoretic Neural Optimizer for Training Residual Networks&#125;,<br />
         &nbsp; author=&#123;Liu, Guan-Horng and Chen, Tianrong and Theodorou, Evangelos A&#125;,<br />
         
            &nbsp; journal=&#123;arXiv preprint arXiv:2007.08880&#125;,<br />
         
         &nbsp; year=&#123;2020&#125;,<br />
         &#125;
      </p>
    </div>

  </div>
</div>
</li></ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-md-2 abbr">
  
    
    <abbr class="badge">CoRL 2017</abbr>
    <!-- <div class="award"></div> -->
    
  
  </div>

  <div id="liu2017learning" class="col-md-9">
    
      <div class="title">Learning end-to-end multimodal sensor policies for autonomous navigation</div>
      <div class="author">
        
          
          
          
          

          
            
              
                <em>Guan-Horng Liu</em>,
              
            
          
        
          
          
          
          

          
            
              
                
                  Avinash Siravuru,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Sai Prabhakar,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Manuela Veloso,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and George Kantor
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Conference on Robot Learning</em>,
      
      
        2017
      
      </div>
      
    



    <div class="links">
    <a class="cite btn btn-sm z-depth-0" role="button">bibtex</a>
    
      <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
    
    
      <a href="http://arxiv.org/abs/1705.10422" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="http://proceedings.mlr.press/v78/liu17a/liu17a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="https://www.youtube.com/watch?v=QAK2lcXjNZc" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Multisensory polices are known to enhance both state estimation and target tracking. However, in the space of end-to-end sensorimotor control, this multi-sensor outlook has received limited attention. Moreover, systematic ways to make policies robust to partial sensor failure are not well explored. In this work, we propose a specific customization of Dropout, called \textitSensor Dropout, to improve multisensory policy robustness and handle partial failure in the sensor-set. We also introduce an additional auxiliary loss on the policy network in order to reduce variance in the band of potential multi- and uni-sensory policies to reduce jerks during policy switching triggered by an abrupt sensor failure or deactivation/activation. Finally, through the visualization of gradients, we show that the learned policies are conditioned on the same latent states representation despite having diverse observations spaces - a hallmark of true sensor-fusion. Simulation results of the multisensory policy, as visualized in TORCS racing game, can be seen here: this https URL.</p>
    </div>
    
    <!-- Hidden abstract block -->

    <div class="cite hidden">
      <p>&#64;inproceedings&#123;liu2017learning,<br />
         &nbsp; title=&#123;Learning end-to-end multimodal sensor policies for autonomous navigation&#125;,<br />
         &nbsp; author=&#123;Liu, Guan-Horng and Siravuru, Avinash and Prabhakar, Sai and Veloso, Manuela and Kantor, George&#125;,<br />
         
            &nbsp; booktitle=&#123;Conference on Robot Learning&#125;,<br />
         
         &nbsp; year=&#123;2017&#125;,<br />
         &#125;
      </p>
    </div>

  </div>
</div>
</li>
<li><div class="row">
  <div class="col-md-2 abbr">
  
    
    <abbr class="badge">CMU Thesis</abbr>
    <!-- <div class="award"></div> -->
    
  
  </div>

  <div id="liu2017high" class="col-md-9">
    
      <div class="title">High Dimensional Planning and Learning for Off-Road Driving</div>
      <div class="author">
        
          
          
          
          

          
            
              <em>Guan-Horng Liu</em>
            
          
        
      </div>

      <div class="periodical">
      
        <em>CMU Robotics Institute Master Thesis</em>,
      
      
        2017
      
      </div>
      
    



    <div class="links">
    <a class="cite btn btn-sm z-depth-0" role="button">bibtex</a>
    
    
    
    
      
      <a href="https://www.ri.cmu.edu/wp-content/uploads/2017/07/Guan-Horng-Liu-thesis.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <!-- Hidden abstract block -->

    <div class="cite hidden">
      <p>&#64;article&#123;liu2017high,<br />
         &nbsp; title=&#123;High Dimensional Planning and Learning for Off-Road Driving&#125;,<br />
         &nbsp; author=&#123;Liu, Guan-Horng&#125;,<br />
         
            &nbsp; journal=&#123;CMU Robotics Institute Master Thesis&#125;,<br />
         
         &nbsp; year=&#123;2017&#125;,<br />
         &#125;
      </p>
    </div>

  </div>
</div>
</li>
<li><div class="row">
  <div class="col-md-2 abbr">
  
    
    <abbr class="badge">RLDM 2017</abbr>
    <!-- <div class="award"></div> -->
    
  
  </div>

  <div id="liu2017higi" class="col-md-9">
    
      <div class="title">Multi-modal Deep Reinforcement Learning with a Novel Sensor-based Dropout</div>
      <div class="author">
        
          
          
          
          

          
            
              
                <em>Guan-Horng Liu</em>,
              
            
          
        
          
          
          
          

          
            
              
                
                  Avinash Siravuru,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Sai Prabhakar,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  George Kantor,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and Manuela Veloso
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Multi-disciplinary Conference on Reinforcement Learning and Decision Making</em>,
      
      
        2017
      
      </div>
      
    



    <div class="links">
    <a class="cite btn btn-sm z-depth-0" role="button">bibtex</a>
    
    
    
    
      
      <a href="https://ghliu.github.io/assets/pdf/2017RLDM.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <!-- Hidden abstract block -->

    <div class="cite hidden">
      <p>&#64;article&#123;liu2017higi,<br />
         &nbsp; title=&#123;Multi-modal Deep Reinforcement Learning with a Novel Sensor-based Dropout&#125;,<br />
         &nbsp; author=&#123;Liu, Guan-Horng and Siravuru, Avinash and Prabhakar, Sai and Kantor, George and Veloso, Manuela&#125;,<br />
         
            &nbsp; journal=&#123;Multi-disciplinary Conference on Reinforcement Learning and Decision Making&#125;,<br />
         
         &nbsp; year=&#123;2017&#125;,<br />
         &#125;
      </p>
    </div>

  </div>
</div>
</li></ol>

  <h2 class="year">2014</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-md-2 abbr">
  
    
    <abbr class="badge">JBE 2014</abbr>
    <!-- <div class="award"></div> -->
    
  
  </div>

  <div id="liu2014bio" class="col-md-9">
    
      <div class="title">A bio-inspired hopping kangaroo robot with an active tail</div>
      <div class="author">
        
          
          
          
          

          
            
              
                <em>Guan-Horng Liu</em>,
              
            
          
        
          
          
          
          

          
            
              
                
                  Hou-Yi Lin,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Huai-Yu Lin,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Shao-Tuan Chen,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and Pei-Chun Lin
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Journal of Bionic Engineering</em>,
      
      
        2014
      
      </div>
      
    



    <div class="links">
    <a class="cite btn btn-sm z-depth-0" role="button">bibtex</a>
    
    
    
    
      
      <a href="http://biorola.me.ntu.edu.tw/pdf/Journal%20papers/2014%20JBE.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <!-- Hidden abstract block -->

    <div class="cite hidden">
      <p>&#64;article&#123;liu2014bio,<br />
         &nbsp; title=&#123;A bio-inspired hopping kangaroo robot with an active tail&#125;,<br />
         &nbsp; author=&#123;Liu, Guan-Horng and Lin, Hou-Yi and Lin, Huai-Yu and Chen, Shao-Tuan and Lin, Pei-Chun&#125;,<br />
         
            &nbsp; journal=&#123;Journal of Bionic Engineering&#125;,<br />
         
         &nbsp; year=&#123;2014&#125;,<br />
         &#125;
      </p>
    </div>

  </div>
</div>
</li>
<li><div class="row">
  <div class="col-md-2 abbr">
  
    
    <abbr class="badge">RSJ 2014</abbr>
    <!-- <div class="award"></div> -->
    
  
  </div>

  <div id="liu2014auto" class="col-md-9">
    
      <div class="title">Autonomous Control of the WAM-V Catamaran Type Unmanned Surface Vehicle: Propulsion System Design</div>
      <div class="author">
        
          
          
          
          

          
            
              
                <em>Guan-Horng Liu</em>,
              
            
          
        
          
          
          
          

          
            
              
                
                  Andre Yuji YASUTOMI,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Alexis HOLGADO,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and Edwardo F FUKUSHIMA
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Annual Conference of the Robotics Society of Japan</em>,
      
      
        2014
      
      </div>
      
    



    <div class="links">
    <a class="cite btn btn-sm z-depth-0" role="button">bibtex</a>
    
    
    
    
      
      <a href="https://ghliu.github.io/assets/pdf/2014RSJ.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <!-- Hidden abstract block -->

    <div class="cite hidden">
      <p>&#64;article&#123;liu2014auto,<br />
         &nbsp; title=&#123;Autonomous Control of the WAM-V Catamaran Type Unmanned Surface Vehicle: Propulsion System Design&#125;,<br />
         &nbsp; author=&#123;Liu, Guan-Horng and YASUTOMI, Andre Yuji and HOLGADO, Alexis and FUKUSHIMA, Edwardo F&#125;,<br />
         
            &nbsp; journal=&#123;Annual Conference of the Robotics Society of Japan&#125;,<br />
         
         &nbsp; year=&#123;2014&#125;,<br />
         &#125;
      </p>
    </div>

  </div>
</div>
</li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0", style="text-align:center; font-size:0.8rem">
    &copy; Copyright 2021 Guan-Horng Liu  .
    
    
    
    Last updated: September 2021.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
